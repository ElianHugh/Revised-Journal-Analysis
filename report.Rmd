---
title: "Journal Analysis"
author: "Elian H. Thiele-Evans, Jennifer L. Beaudry"
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes:
   - \usepackage{setspace}
   - \doublespacing
output:
   pdf_document
---

```{r, include = FALSE}
# Setup
box::use(
    targets[tar_read, tar_load],
    knitr[opts_chunk],
    dplyr[...]
)

opts_chunk$set(
    fig.width = 12, fig.height = 8, fig.path = "Figs/",
    echo = FALSE, warning = FALSE, message = FALSE
)
```

```{r quantileData, include = FALSE}
tar_load(aggregatedPolicies)
vlow <- aggregatedPolicies %>%
    filter(ScoreGrade == "Very Low") %>%
    select(ScoreMin, ScoreMax) %>%
    .[1,] %>%
    as.character(.)
low <- aggregatedPolicies %>%
    filter(ScoreGrade == "Low") %>%
    select(ScoreMin, ScoreMax) %>%
    .[1, ] %>%
    as.character(.)
medium <- aggregatedPolicies %>%
    filter(ScoreGrade == "Medium") %>%
    select(ScoreMin, ScoreMax) %>%
    .[1, ] %>%
    as.character(.)
high <- aggregatedPolicies %>%
    filter(ScoreGrade == "High") %>%
    select(ScoreMin, ScoreMax) %>%
    .[1, ] %>%
    as.character(.)
vhigh <- aggregatedPolicies %>%
    filter(ScoreGrade == "Very High") %>%
    select(ScoreMin, ScoreMax) %>%
    .[1, ] %>%
    as.character(.)
```

As we were interested in how journal 'prestige' aligns with open science policy, we conducted a cross-comparison of journal prestige and open science initiatives. We took the top 10% of journals[^1] from Scopus' database (measured through 'CiteScore', Scopus' version of impact factor) in order to examine the distribution of open science practices in "prestigious" journals. We then measured open science initiatives through a combination of open science (TOP factor) and open access policies (Sherpa/ROMEO). We gave each journal an open science score, which was an aggregation of the total number of open science policies a journal implements. We then categorised the open science scores into quantiles: very low (`r vlow[1]`-`r vlow[2]`), low (`r low[1]`-`r low[2]`), medium (`r medium[1]`-`r medium[2]`), high (`r high[1]`-`r high[2]`), and very high (`r vhigh[1]`-`r vhigh[2]`). Figure 1 displays the distribution of open science policy, compared to CiteScore.

[^1]: 90% of CiteScores fall between 0 and 6

**Figure 1**
```{r citeGraph, out.width = '80%'}
tar_read(citeRidge)
```

As per Figure 1, the distribution of CiteScore is similar across 'very low' to 'high' groups, with the exception being the 'very high' group (*SD* = `r aggregatedPolicies %>% filter(ScoreGrade == "Very High")  %>% pull(CiteScore)  %>% sd() %>% round(., digits = 2)`). It is conceivable that, in light of high-profile replication failures, higher impact journals have begun to adopt open science policy in some form, explaining the larger standard deviation of the 'very high' group.

We performed bootstrap resampling to compare the similarity of the analysis sample to a random sample from the CiteScore database. Each bootstrapped sample was of identical size to the analysis sample, and was limited to the top 10% of cite scores. Figure 2 displays the distribution of bootstrapped sample means, and where in the distribution the analysis sample mean falls.

**Figure 2**
```{r bootGraphMean, out.width = '70%'}
tar_read(bootGraphMean)
```

The bootstrap resampling indicates that the journals sampled from the TOP database fall in the 99% CI for journal means, albeit on the higher end of bootstrapped samples.

# Future

As the TOP database is expanded, the analysis conducted can be expanded to include more journals. Moreover, the level of policy implementation could be a future project, as the current work did not have the ability to differentiate and assess whether journals were adopting a broad range of low or high level policies.