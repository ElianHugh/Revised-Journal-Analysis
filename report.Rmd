---
title: "Journal Analysis"
author: "Elian H. Thiele-Evans, Jennifer L. Beaudry"
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes:
   - \usepackage{setspace}
   - \doublespacing
output:
   pdf_document
---

```{r, include = FALSE}
# Setup
box::use(
    targets[tar_read, tar_load],
    knitr[opts_chunk],
    dplyr[...],
    readr[read_csv, col_skip, cols],
    topapi
)

opts_chunk$set(
    fig.width = 12, fig.height = 8, fig.path = "Figs/",
    echo = FALSE, warning = FALSE, message = FALSE
)
```

```{r sampleData, include = FALSE}
orig_cite_n <- read_csv("Data/CiteScore.csv",
    col_types = cols(
        `Scopus Source ID` = col_skip(),
        `Scholarly Output` = col_skip(),
        `Percent Cited` = col_skip(),
        SNIP = col_skip(),
        `Scopus ASJC Code (Sub-subject Area)` = col_skip(),
        Percentile = col_skip(),
        RANK = col_skip(),
        `Rank Out Of` = col_skip(),
        Type = col_skip(),
        `Open Access` = col_skip(),
        Quartile = col_skip(),
        `URL Scopus Source ID` = col_skip(),
        `Citation Count` = col_skip(),
        SJR = col_skip()
    )
) %>%
    nrow(.)

orig_top_n <- topapi$full_data() %>%
    nrow(.)

```

```{r quantileData, include = FALSE}
tar_load(aggregated_policies)
tar_load(cite_score_dat)

min_score <- cite_score_dat %>%
    slice_max(CiteScore, n = nrow(.) * 0.1) %>%
    pull(CiteScore) %>%
    range() %>%
    .[1]

top10_cite <- cite_score_dat %>%
    filter(CiteScore >= min_score)

total_sample <- aggregated_policies %>%
    ungroup() %>%
    filter(CiteScore >= min_score) %>%
    nrow()

vlow <- aggregated_policies %>%
    filter(ScoreGrade == "Very Low") %>%
    select(ScoreMin, ScoreMax) %>%
    .[1, ] %>%
    as.character(.)

low <- aggregated_policies %>%
    filter(ScoreGrade == "Low") %>%
    select(ScoreMin, ScoreMax) %>%
    .[1, ] %>%
    as.character(.)

medium <- aggregated_policies %>%
    filter(ScoreGrade == "Medium") %>%
    select(ScoreMin, ScoreMax) %>%
    .[1, ] %>%
    as.character(.)

high <- aggregated_policies %>%
    filter(ScoreGrade == "High") %>%
    select(ScoreMin, ScoreMax) %>%
    .[1, ] %>%
    as.character(.)

vhigh <- aggregated_policies %>%
    filter(ScoreGrade == "Very High") %>%
    select(ScoreMin, ScoreMax) %>%
    .[1, ] %>%
    as.character(.)

show_range <- function(low, high) {
    if (as.numeric(low) != as.numeric(high)) {
        ret <- sprintf(
            "%s - %s",
            low,
            high
        )
        return(ret)
    } else {
        return(low)
    }
}
```

As we were interested in how journal "prestige" aligns with open science policy, we conducted a cross-comparison of journal prestige and open science initiatives. We took the top 10% of journals[^1] from a Scopus database (*SD* = `r round(sd(top10_cite$CiteScore))`; *n* = `r nrow(top10_cite)`; measured through "CiteScore", Scopus' version of impact factor) in order to examine the distribution of open science practices in "prestigious" journals. We then measured open science initiatives through a combination of open science (TOP factor) and open access policies (Sherpa/ROMEO). We gave each journal an open science policy score, which was an aggregation of the **total** number of open science policies a journal adopts (*not* the level of policy). We then categorised the open science policy scores into quintiles: very low (`r show_range(vlow[1], vlow[2])`), low (`r show_range(low[1], low[2])`), medium (`r show_range(medium[1], medium[2])`), high (`r show_range(high[1], high[2])`), and very high (`r show_range(vhigh[1], vhigh[2])`). We reached the final journal sample (*n* = `r total_sample`) by performing the following:

[^1]: The other 90% of CiteScores in the database fall between 0 and 6; *N* = `r orig_cite_n`

1. Retrieve CiteScore (*N* = `r orig_cite_n`) and TOP Factor (*N* = `r orig_top_n`) data files[^2]
3. Filter the journals to those in the top 10% of CiteScores on Scopus
2. Remove journals from TOP that do not have an associated CiteScores on the modified CiteScore file
4. Retrieve SHERPA/RoMEO policies through their API, removing journals that did not have any OA policies listed

[^2]: A helper R package was created for the handling of the TOP dataset [topapi](https://github.com/ElianHugh/topapi)

Figure 1 displays the distribution of open science policy score, compared to CiteScore.

\newpage

## Figure 1

```{r citeGraph, out.width = "80%"}
tar_read(cite_ridge)
```

```{r}
other_sd <- aggregated_policies %>%
    filter(ScoreGrade != "Very High") %>%
    group_by(ScoreGrade) %>%
    summarise(StnD = sd(CiteScore)) %>%
    pull(StnD) %>%
    round(., digits = 2)
v_high_sd <- aggregated_policies %>%
    filter(ScoreGrade == "Very High") %>%
    pull(CiteScore) %>%
    sd() %>%
    round(., digits = 2)
```

As per Figure 1, the journals in the very high group show considerable varation in their CiteScores (*SD* = `r v_high_sd`). The journals of all other categories of open science policy scores show similar distirubtions to eachother (*SD* = `r min(other_sd)` - `r max(other_sd)`). It is conceivable that, in light of high-profile replication failures, higher impact journals have begun to adopt open science policy in some form, explaining the larger standard deviation of the "very high" group.

```{r}
bootSize <- aggregated_policies %>%
    ungroup() %>%
    filter(CiteScore >= min_score) %>%
    distinct(Title, .keep_all = TRUE) %>%
    nrow(.)
```

## Did our sample reflect the CiteScore distributions of other journals?

We performed bootstrap resampling to compare the similarity of the analysis sample to a random sample from the CiteScore database. We did this in order to ensure that the journal sample had similar properties to a random sample taken from the top 10% of CiteScores. Each bootstrapped sample was of identical size to the analysis sample (*n* = `r bootSize`), and was limited to the top 10% of CiteScores in the Scopus database. Figure 2 displays the distribution of bootstrapped sample means, and where in the distribution the analysis sample mean falls.

\newpage

### Figure 2

```{r bootGraphMean, out.width = "70%"}
tar_read(boot_graph_mean)
```

The bootstrap resampling indicates that the journals sampled from the TOP database fall in the 99% CI for journal means, albeit on the higher end of bootstrapped samples.

# Future Directions

As the TOP database is expanded, our analysis can be expanded to include more journals. Moreover, future research could explore the level of open science policy adoption, as the current work did not differentiate whether journals were adopting a broad range of low or high level policies.

\newpage

# Data Sources

Center for Open science (2021). TOP Factor [Data set]. https://osf.io/qatkz/

Jisc. (2021). SHERPA/RoMEO [Data set]. https://v2.sherpa.ac.uk/romeo/

Scopus. (2021). CiteScore [Data set]. https://www.scopus.com/sources

# Packages

\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\noindent

Aust, F. & Barth, M. (2020). papaja: Prepare reproducible APA journal articles with R Markdown. R package version 0.1.0.9997, retrieved from https://github.com/crsh/papaja

Claus O. Wilke (2021). ggridges: Ridgeline Plots in 'ggplot2'. R package version 0.5.3. https://CRAN.R-project.org/package=ggridges

David Robinson (2020). fuzzyjoin: Join Tables Together on Inexact Matching. R package version 0.1.6. https://CRAN.R-project.org/package=fuzzyjoin

Konrad Rudolph (2021). box: Write Reusable, Composable and Modular R Code. R package version 1.0.2. https://CRAN.R-project.org/package=box

Kropko, Jonathan and Harden, Jeffrey J. (2020). coxed: Duration-Based Quantities of Interest for the Cox Proportional Hazards Model. R package version 0.3.3. https://CRAN.R-project.org/package=coxed

Kun Ren (2016). rlist: A Toolbox for Non-Tabular Data Manipulation. R package version 0.4.6.1. https://CRAN.R-project.org/package=rlist

Landau, W. M., (2021). The targets R package: a dynamic Make-like function-oriented pipeline toolkit for reproducibility and high-performance computing. Journal of Open Source Software, 6(57), 2959, https://doi.org/10.21105/joss.02959

Luke Tierney, A. J. Rossini, Na Li and H. Sevcikova (2018). snow: Simple Network of Workstations. R package version 0.4-3. https://CRAN.R-project.org/package=snow

R Core Team (2021). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.

Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686
